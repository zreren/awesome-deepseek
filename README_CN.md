# DeepSeek 资源汇总

[English](README.md) | [中文](README_CN.md)

精选的 DeepSeek AI 模型及其生态系统相关资源、工具和应用的汇总列表。

## 目录

- [DeepSeek 资源汇总](#deepseek-资源汇总)
  - [目录](#目录)
  - [简介](#简介)
  - [模型](#模型)
  - [论文](#论文)
    - [基础模型](#基础模型)
    - [代码模型](#代码模型)
  - [使用指南](#使用指南)
  - [集成方案](#集成方案)
  - [快速开始](#快速开始)
  - [社区](#社区)

## 简介

DeepSeek 是一系列强大的 AI 模型家族，专注于代码生成、自然语言处理等多种任务。本仓库旨在收集和整理资源，帮助开发者和研究人员充分利用 DeepSeek 的能力。

## 模型

- **R1模型下载**：https://huggingface.co/collections/deepseek-ai/deepseek-r1-678e1e131c0169c0bc89728d 
- **DeepSeek Coder**: 基于高质量代码数据训练的代码生成模型
- **DeepSeek LLM**: 通用大语言模型
- **DeepSeek MoE**: 基于混合专家的增强性能模型

## 论文

### 基础模型
- [DeepSeek 技术报告 R1](DeepSeek-R1-技术报告中文版-由deepseek翻译.pdf) - DeepSeek 模型的综合技术报告（中文版）
- [DeepSeek Technical Report R1](DeepSeek_R1.pdf) - DeepSeek 模型的综合技术报告（英文版）
- [DeepSeek LLM: Scaling Open-Source Language Models with Longtermism](https://arxiv.org/abs/2401.02954) - 介绍了 DeepSeek 基础模型的训练方法和创新点
- [DeepSeek-MoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models](https://arxiv.org/abs/2401.12246) - 详细描述了 DeepSeek MoE 模型的架构设计和训练策略

### 代码模型
- [DeepSeek-Coder: When the Large Language Model Meets Programming](https://arxiv.org/abs/2401.14196) - 深入探讨了 DeepSeek Coder 的技术细节和性能表现

## 使用指南
- [DeepSeek 最佳实践与提示词指南](https://mp.weixin.qq.com/s/qy25l_zj0HRDTt4vQh8zmA) - 全面的提示词编写和使用模式指南
- [看好了，这才是DeepSeek的正确用法！不要再写传统的提示词了](https://www.opacity.ink/cn/blog/deepseek-prompt)

## 集成方案
- [DeepSeek-Claude](https://github.com/getasterisk/deepclaude) - DeepSeek 与 Claude 的集成增强方案

## 快速开始

开始使用 DeepSeek 模型：

1. 访问[官方网站](https://deepseek.ai)
2. 查看[模型文档](https://github.com/deepseek-ai)
3. 通过可用的 API 或实现来试用模型

## 社区

- [Discord 社区](https://discord.gg/deepseek)
- [GitHub 组织](https://github.com/deepseek-ai)
- [Twitter](https://twitter.com/deepseek_ai) 